{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project : Profitable App profiles for the app store and Google Play Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file_1 = open('AppleStore.csv')\n",
    "open_file_2 = open('googleplaystore.csv')\n",
    "from csv import reader\n",
    "read_1 = reader(open_file_1)\n",
    "read_2 = reader(open_file_2)\n",
    "apple_data = list(read_1)\n",
    "google_data = list(read_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jazz Wi-Fi', 'COMMUNICATION', '3.4', '49', '4.0M', '10,000+', 'Free', '0', 'Everyone', 'Communication', 'February 10, 2017', '0.1', '2.3 and up']\n",
      "\n",
      "\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_data,10471,10473,True)\n",
    "explore_data(apple_data,0,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_header = google_data[0]\n",
    "for row in google_data[1:]:\n",
    "    if len(google_header)!=len(row):\n",
    "        print(row)\n",
    "        print(google_data.index(row))\n",
    "        print(len(row))\n",
    "        print(len(google_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del google_data[10473]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have to find out the different duplicate entries in the whole data set, previously we found that there was a column entry missing from a record hence we removed it, now we have to check for duplicates. Using in Operator and trailing through the data we would be able to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings']\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'Coloring book moana', 'U Launcher Lite â€“ FREE Live Cool Themes, Hide Apps', 'Sketch - Draw & Paint']\n"
     ]
    }
   ],
   "source": [
    "duplicate_app= []\n",
    "unique_app=[]\n",
    "for row in google_data[1:]:\n",
    "    name = row[0]\n",
    "    if name not in unique_app:\n",
    "        unique_app.append(name)\n",
    "    else:\n",
    "        duplicate_app.append(name)\n",
    "print(duplicate_app[:4])\n",
    "print(unique_app[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decide criterion on which we will remove duplicate, mostly the latest data must be saved rest can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "reviews_max = {}\n",
    "for row in google_data[1:]:\n",
    "    name = row[0]\n",
    "    n_review = float(row[3])\n",
    "    if name in reviews_max and reviews_max[name]<n_review:\n",
    "        reviews_max[name] = n_review\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_review\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "for row in google_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        android_clean.append(row)\n",
    "        already_added.append(name)\n",
    "print(len(android_clean))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the Data : 1. Check for the Column missing : Len of header == len of row\n",
    "2. Check for double entries: make 2 list and append in it duplicate and unique.\n",
    "3. Find the criteria to remove the duplicate and make adictionary of it\n",
    "4. make two list, added and cleaned, go through data and check for the dictionaries requirement and in added list, then append it in Cleaned data list and also append name in already added.\n",
    "5. Check for the Region language in the data , we dont want the data to be from outside country, english is from 0 to 127\n",
    "6.Isolating the data as required to the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_english(a_string):\n",
    "    for word in a_string:\n",
    "        if ord(word)>127:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "check_english('Instachat ðŸ˜œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9623\n",
      "6273\n",
      "8873\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "cleaned_google_data = []\n",
    "cleaned_apple_data = []\n",
    "for row in android_clean:\n",
    "    name = row[0]\n",
    "    if check_english(name)==True:\n",
    "        cleaned_google_data.append(row)\n",
    "print(len(cleaned_google_data))\n",
    "        \n",
    "for row in apple_data[1:]:\n",
    "    name = row[1]\n",
    "    if check_english(name)==True:\n",
    "        cleaned_apple_data.append(row)\n",
    "print(len(cleaned_apple_data))\n",
    "\n",
    "#Finding only the Free apps in both data set\n",
    "final_google_data = []\n",
    "final_apple_data = []\n",
    "for row in cleaned_google_data:\n",
    "    price = row[7]\n",
    "    if price == '0.0' or price == '0' or price == '$0' or price == '$0.0':\n",
    "        final_google_data.append(row)\n",
    "for row in cleaned_apple_data:\n",
    "    price = row[4]\n",
    "    if price == '0.0' or price == '0' or price == '$0' or price=='$0.0':\n",
    "        final_apple_data.append(row)\n",
    "print(len(final_google_data))\n",
    "print(len(final_apple_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FInding the app profile that fits both Google play and IOs\n",
    "To Minimize risk and overhead, validation strategy for app idea has three steps\n",
    "1 Build a minimal andriod version of the app and add it to Google play\n",
    "2 If the response it good, develop it further\n",
    "3 If profitable after six months, build an iOS version\n",
    "\n",
    "Inspect both data set and find columns you could generate frequency table to determine mos common genres in each market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 1897\n",
      "Entertainment : 263\n",
      "Photo & Video : 161\n",
      "Education : 118\n",
      "Social Networking : 112\n",
      "Utilities : 89\n",
      "Shopping : 85\n",
      "Sports : 70\n",
      "Health & Fitness : 68\n",
      "Music : 67\n",
      "Productivity : 58\n",
      "Lifestyle : 56\n",
      "News : 45\n",
      "Travel : 39\n",
      "Finance : 39\n",
      "Weather : 29\n",
      "Food & Drink : 29\n",
      "Book : 19\n",
      "Reference : 17\n",
      "Business : 17\n",
      "Navigation : 9\n",
      "Medical : 7\n",
      "Catalogs : 6\n",
      "\n",
      "\n",
      "1,000,000+ : 1390\n",
      "100,000+ : 1025\n",
      "10,000,000+ : 934\n",
      "10,000+ : 904\n",
      "1,000+ : 749\n",
      "100+ : 615\n",
      "5,000,000+ : 605\n",
      "500,000+ : 493\n",
      "50,000+ : 428\n",
      "5,000+ : 400\n",
      "10+ : 315\n",
      "500+ : 288\n",
      "50,000,000+ : 203\n",
      "100,000,000+ : 189\n",
      "50+ : 170\n",
      "5+ : 70\n",
      "1+ : 46\n",
      "500,000,000+ : 24\n",
      "1,000,000,000+ : 20\n",
      "0+ : 4\n",
      "0 : 1\n"
     ]
    }
   ],
   "source": [
    "#passed dataset must not have header\n",
    "def freq_table(dataset,index):\n",
    "    f_table = {}\n",
    "    for row in dataset:\n",
    "        key = row[index]\n",
    "        if key in f_table:\n",
    "            f_table[key]+=1\n",
    "        else:\n",
    "            f_table[key]=1\n",
    "    return f_table\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])   \n",
    "display_table(final_apple_data,11)\n",
    "print('\\n')\n",
    "display_table(final_google_data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Networking\n",
      "67731.21428571429\n",
      "\n",
      "\n",
      "Photo & Video\n",
      "28264.888198757762\n",
      "\n",
      "\n",
      "Games\n",
      "22199.308381655246\n",
      "\n",
      "\n",
      "Music\n",
      "56482.02985074627\n",
      "\n",
      "\n",
      "Reference\n",
      "79350.4705882353\n",
      "\n",
      "\n",
      "Health & Fitness\n",
      "22278.352941176472\n",
      "\n",
      "\n",
      "Weather\n",
      "50477.137931034486\n",
      "\n",
      "\n",
      "Utilities\n",
      "17058.719101123595\n",
      "\n",
      "\n",
      "Travel\n",
      "28959.5641025641\n",
      "\n",
      "\n",
      "Shopping\n",
      "26586.788235294116\n",
      "\n",
      "\n",
      "News\n",
      "20303.666666666668\n",
      "\n",
      "\n",
      "Navigation\n",
      "57393.555555555555\n",
      "\n",
      "\n",
      "Lifestyle\n",
      "15023.089285714286\n",
      "\n",
      "\n",
      "Entertainment\n",
      "13549.794676806083\n",
      "\n",
      "\n",
      "Food & Drink\n",
      "29886.931034482757\n",
      "\n",
      "\n",
      "Sports\n",
      "22680.2\n",
      "\n",
      "\n",
      "Book\n",
      "29310.736842105263\n",
      "\n",
      "\n",
      "Finance\n",
      "29048.615384615383\n",
      "\n",
      "\n",
      "Education\n",
      "7003.983050847458\n",
      "\n",
      "\n",
      "Productivity\n",
      "20303.310344827587\n",
      "\n",
      "\n",
      "Business\n",
      "7491.117647058823\n",
      "\n",
      "\n",
      "Catalogs\n",
      "2669.3333333333335\n",
      "\n",
      "\n",
      "Medical\n",
      "525.4285714285714\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_frequency_table = freq_table(final_apple_data,11)\n",
    "\n",
    "for genre in apple_frequency_table:\n",
    "    total_rating = 0\n",
    "    len_genre = 0\n",
    "    for row in final_apple_data:\n",
    "        genre_app = row[11]\n",
    "        if genre_app == genre:\n",
    "            len_genre+=1\n",
    "            total_rating +=float(row[5])\n",
    "    avg_user_rating = total_rating/len_genre\n",
    "    print(genre)\n",
    "    print(avg_user_rating)\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    #calculated average review per genre, to knnow the interaction between the apps and the their users to find outthe profitablity.\n",
    "    #more the interaction more the review , more we can say, downloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
